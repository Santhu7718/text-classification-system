# ğŸ“© Text Classification System (SMS Spam Detection)

## ğŸ“Œ Project Overview

This project is an **end-to-end Machine Learningâ€“based Text Classification System** designed to classify SMS messages as **Spam** or **Ham (Not Spam)**.  
It demonstrates the complete ML workflow â€” from data preprocessing and feature extraction to model training, evaluation, and deployment using **Streamlit**.

The project was developed as part of an **AI/ML Engineer technical assignment** and follows industry-standard practices.

---

## ğŸ¯ Problem Statement

Spam messages cause inconvenience, fraud, and security risks.  
The goal of this project is to **automatically detect spam SMS messages** using Natural Language Processing (NLP) and Machine Learning techniques.

---

## ğŸ“‚ Project Structure

```text
text-classification-system/
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ SMSSpamCollection
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_data_loading.ipynb
â”‚   â”œâ”€â”€ 02_text_preprocessing.ipynb
â”‚   â”œâ”€â”€ 03_feature_extraction.ipynb
â”‚   â”œâ”€â”€ 04_model_training.ipynb
â”‚   â””â”€â”€ 05_model_evaluation.ipynb
â”‚
â”œâ”€â”€ App.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md

---
```
## ğŸ“Š Dataset Information

- **Dataset Name:** SMS Spam Collection  
- **Source:** UCI Machine Learning Repository  
- **Total Messages:** 5,572  

### Class Distribution
- **Ham:** 4,825  
- **Spam:** 747  

The dataset is slightly imbalanced and is handled using **stratified train-test splitting** to preserve class proportions.

---

## ğŸ§  Workflow Explanation

### 1ï¸âƒ£ Data Loading
- Dataset loaded using **Pandas**
- Tab-separated file format
- Columns:
  - `label` â†’ spam / ham
  - `text` â†’ SMS content

**Notebook:** `01_data_loading.ipynb`

---

### 2ï¸âƒ£ Text Preprocessing
Text cleaning performed using **NLTK**:
- Lowercasing text
- Removing numbers
- Removing punctuation and special characters
- Tokenization
- Stopword removal
- Reconstructing cleaned text

**Notebook:** `02_text_preprocessing.ipynb`

---

### 3ï¸âƒ£ Feature Extraction
- TF-IDF Vectorization applied to text
- Maximum features limited to **3000**
- Efficient handling of sparse text data

**Notebook:** `03_feature_extraction.ipynb`

---

### 4ï¸âƒ£ Model Training
Models trained:
- Multinomial Naive Bayes
- Logistic Regression

**Training Strategy:**
- 80% Training
- 20% Testing
- Stratified split on labels

**Notebook:** `04_model_training.ipynb`

---

### 5ï¸âƒ£ Model Evaluation
Evaluation metrics used:
- Accuracy
- Precision
- Recall
- F1-score
- Confusion Matrix

**Notebook:** `05_model_evaluation.ipynb`

Final model selected: **Logistic Regression**  
Reason: Better generalization and fewer false positives.

---
##How to run this locally : 
1.Clone the repository : 

```git clone https://github.com/Santhu7718/text-classification-system.git
cd text-classification-system```

